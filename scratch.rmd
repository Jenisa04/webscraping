---
title: "scratch"
author: "Derek Sollberger"
date: "2/9/2021"
output: html_document
---

```{r}
library("kableExtra")
library("rtweet")
library("rvest")
library("tidyverse")
```

```{r}
# example from README at https://github.com/tidyverse/rvest
# Start by reading a HTML page with read_html():
starwars <- read_html("https://rvest.tidyverse.org/articles/starwars.html")

# Then find elements that match a css selector or XPath expression
# using html_elements(). In this example, each <section> corresponds
# to a different film
films <- starwars %>% html_nodes("section")
films
#> {xml_nodeset (7)}
#> [1] <section><h2 data-id="1">\nThe Phantom Menace\n</h2>\n<p>\nReleased: 1999 ...
#> [2] <section><h2 data-id="2">\nAttack of the Clones\n</h2>\n<p>\nReleased: 20 ...
#> [3] <section><h2 data-id="3">\nRevenge of the Sith\n</h2>\n<p>\nReleased: 200 ...
#> [4] <section><h2 data-id="4">\nA New Hope\n</h2>\n<p>\nReleased: 1977-05-25\n ...
#> [5] <section><h2 data-id="5">\nThe Empire Strikes Back\n</h2>\n<p>\nReleased: ...
#> [6] <section><h2 data-id="6">\nReturn of the Jedi\n</h2>\n<p>\nReleased: 1983 ...
#> [7] <section><h2 data-id="7">\nThe Force Awakens\n</h2>\n<p>\nReleased: 2015- ...

# Then use html_element() to extract one element per film. Here
# we the title is given by the text inside <h2>
title <- films %>% 
  html_nodes("h2") %>% 
  html_text()
title
#> [1] "The Phantom Menace"      "Attack of the Clones"   
#> [3] "Revenge of the Sith"     "A New Hope"             
#> [5] "The Empire Strikes Back" "Return of the Jedi"     
#> [7] "The Force Awakens"

# Or use html_attr() to get data out of attributes. html_attr() always
# returns a string so we convert it to an integer using a readr function
episode <- films %>% 
  html_nodes("h2") %>% 
  html_attr("data-id") %>% 
  readr::parse_integer()
episode
#> [1] 1 2 3 4 5 6 7
```

```{r}
#http://library.ucmerced.edu/about/contact/staff
raw_library_HTML <- read_html("http://library.ucmerced.edu/about/contact/staff")
library_nodes <- raw_library_HTML %>% html_nodes("div")
#raw_text <- raw_library_HTML %>% html_nodes("div") %>% html_text()
# job_titles <- raw_library_HTML %>% 
#   html_nodes("div") %>% 
#   grep("views-field views-field-title", ., value = TRUE)
# job_titles <- raw_library_HTML %>%
#   html_nodes("span") %>%
#   grep("field-content normal-serif", ., value = TRUE)
  
# job_titles <- raw_library_HTML %>%
#   html_nodes("span") %>%
#   html_text()
# job_titles <- raw_library_HTML %>%
#   html_nodes("span.normal-serif") %>%
#   html_text()
employees <- raw_library_HTML %>%
  html_nodes("div.views-field-title") %>%
  html_text(trim = TRUE)

job_titles <- raw_library_HTML %>%
  html_nodes("div.views-field-field-job-title") %>%
  html_text(trim = TRUE)

contact <- raw_library_HTML %>%
  html_nodes("div.views-field-field-email") %>%
  html_text(trim = TRUE)
```

```{r}
library_df <- data.frame(employees, job_titles, contact)
library_df
```

```{r}
library_df %>%
  kbl() %>%
  kable_paper("hover", full_width = F)
  
```


```{r}
# https://en.wikipedia.org/wiki/University_of_California
raw_wikipedia_HTML <- read_html("https://en.wikipedia.org/wiki/University_of_California")

wikipedia_page_tables <- raw_wikipedia_HTML %>%
  html_nodes("table")

ranking_table <- wikipedia_page_tables[[5]] %>% html_table(fill = TRUE)

ranking_table %>%
  kbl() %>%
  kable_paper("hover", full_width = F)
```


```{r, eval = FALSE}
# https://postsecret.com/
raw_postsecret_HTML <- read_html("https://postsecret.com/")

image_links <- raw_postsecret_HTML %>% html_nodes("img")
image_urls <- image_links %>% html_attr("src")

# image_urls <- image_urls[str_detect(image_urls, "jpg")]
# clean_image_urls <- image_urls %>%
#   str_subset("jpg") %>%
#   str_split("?")
# clean_image_urls <- image_urls %>%
#   str_match("jpg") %>%
#   str_extract("[^?]+")

for(i in 1:length(image_urls)){
  download.file(image_urls[i], paste0("images/ps",i,".jpg"))
}
```











```{r, eval = FALSE}
# https://github.com/ropensci/rtweet

# search hashtag
tweet_df <- search_tweets("#ucmerced", n = 100, include_rts = FALSE)
# tweet_df <- search_tweets("#ucmerced", n = 10000, include_rts = FALSE)
```

```{r, eval = FALSE}
# time series plot
tweet_df %>% ts_plot()
```

```{r, eval = FALSE}
# get following (from)
ucm_following <- get_friends("ucmerced")

# explore these user IDs
ucm_following_data <- lookup_users(ucm_following$user_id)
```

```{r, eval = FALSE}
ucm_followers <- get_followers("ucmerced", n = 1000)

ucm_followers_sample <- ucm_followers %>% slice_sample(prop = 0.05)

ucm_followers_data <- lookup_users(ucm_followers_sample$user_id)
```

```{r, eval = FALSE}
#timelines (most recent tweets of a user)
ucm_timeline <- get_timeline("ucmerced", n = 1000)
```

```{r, eval = FALSE}
ucm_timeline %>%
  select(created_at, text) %>%
  kbl(caption = "ucmerced account tweets") %>%
  kable_classic(full_width = TRUE, html_font = "Cambria")
```

```{r, eval = FALSE}
ucm_timeline %>%
  filter(str_detect(text, "Black")) %>%
  kbl(caption = "ucmerced account tweets") %>%
  kable_classic(full_width = TRUE, html_font = "Cambria")
```

```{r, eval = FALSE}
ucm_timeline %>%
  select(favorite_count, created_at, text) %>%
  arrange(desc(favorite_count)) %>%
  kbl(caption = "ucmerced account tweets") %>%
  kable_classic(full_width = TRUE, html_font = "Cambria")
```

